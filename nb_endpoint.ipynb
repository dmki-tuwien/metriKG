{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173cfe1f",
   "metadata": {},
   "source": [
    "Jupyter Notebook that executes metric calculations for locally uploaded RDF files.\n",
    "\n",
    "It imports functions from my_metrics.py and metrics_loader.py, computes selected metrics,\n",
    "\n",
    "and writes the resulting metric table to a CSV file (consumed by the Streamlit app)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d9e07",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (will get overwritten)\n",
    "\n",
    "# `endpoint_url`: URL of the SPARQL endpoint that will be queried for the ontology data.\n",
    "# This is where the ontology is hosted and the metrics will be calculated based on its data.\n",
    "# The value will be overwritten when the notebook runs with an actual SPARQL endpoint URL.\n",
    "endpoint_url = \"https://example.org/sparql\"\n",
    "\n",
    "# `default_graph`: The default graph used for the SPARQL query. This parameter is optional.\n",
    "# If not provided, the query might use the default graph from the endpoint.\n",
    "# It will be overwritten with a specific graph name if needed for the SPARQL query.\n",
    "default_graph = \"\" # optional\n",
    "# `metric_key`: The key that identifies which metric to calculate from the `DISPATCH` dictionary.\n",
    "# The available options will be specified in the code, such as 'paths_depth', 'ont_tangledness', etc.\n",
    "# This will be overwritten by the desired metric key for the analysis.\n",
    "metric_key    = \"paths_depth\"\n",
    "# `output_csv`: The name of the CSV file where the calculated metrics will be saved.\n",
    "# This will be overwritten with a specific file path where the results will be stored.\n",
    "output_csv    = \"metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33aef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, scrapbook as sb\n",
    "import my_metrics as mm\n",
    "\n",
    "# Mapping: a dictionary that associates different metrics with their corresponding functions from `my_metrics` module.\n",
    "DISPATCH = {\n",
    "    \"paths_depth\":     mm.paths_depth_endpoint,\n",
    "    \"ont_tangledness\":     mm.ont_tangledness_endpoint,\n",
    "    \"degree_variance\": mm.degree_variance_endpoint,\n",
    "    \"primitives\":      mm.primitives_endpoint,\n",
    "    \"depth_of_inheritance_tree\": mm.depth_of_inh_tree_endpoint,\n",
    "    \"tbox\":            mm.tbox_endpoint,\n",
    "    \"abox\":            mm.abox_endpoint,\n",
    "    \"cohesion\":        mm.cohesion_endpoint,\n",
    "}\n",
    "\n",
    "# Retrieving the corresponding calculation function based on the metric key (`metric_key`).\n",
    "function = DISPATCH.get(metric_key)\n",
    "# If the metric is not present in the DISPATCH dictionary, an error will be raised.\n",
    "assert function, f\"Unknown metric: {metric_key}\"\n",
    "\n",
    "# Calculating the metric by calling the corresponding function.\n",
    "# The endpoint URL (`endpoint_url`) and an optional default graph (`default_graph`) are passed as parameters.\n",
    "try:\n",
    "    df = function(endpoint_url, default_graph or None)\n",
    "\n",
    "except Exception as e:\n",
    "    # Error handling: If an error occurs during metric calculation, en exception is raised\n",
    "    raise e\n",
    "\n",
    "\n",
    "# Saving the calculated results in the DataFrame `df` as a CSV file.\n",
    "# `index=False` means that the DataFrame index will not be included in the CSV file.\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Displaying calculated metrics in streamlit environment.\n",
    "sb.glue(\"metrics_table\", df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
